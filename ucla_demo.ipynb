{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/sukun/ucla_github/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load ucla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ucla_data(path):\n",
    "    train_1 = load_data(path+'new_xyz_transform_skel_1.json')\n",
    "    train_2 = load_data(path+'new_xyz_transform_skel_2.json')\n",
    "    train_data = {**train_1,**train_2}\n",
    "    # train data\n",
    "    for key in train_data.keys():\n",
    "        train_data[key] = np.asarray(train_data[key])\n",
    "    \n",
    "    # test data\n",
    "    test_data = load_data(path+'new_xyz_transform_skel_3.json')\n",
    "    for key in test_data.keys():\n",
    "        test_data[key] = np.asarray(test_data[key])\n",
    "    # delete bad data\n",
    "    del train_data['a02_s09_e04_v02']\n",
    "    del test_data['a02_s09_e04_v03']\n",
    "    # size of training and test data\n",
    "    print(\"Size of training data: \", len(train_data))\n",
    "    print(\"Size of test data: \", len(test_data))\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize ucla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ucla(video):\n",
    "    max_60 = np.amax(video, axis=0)\n",
    "    min_60 = np.amin(video, axis=0)\n",
    "    max_x = np.max([max_60[i] for i in range(0,60,3)])\n",
    "    max_y = np.max([max_60[i] for i in range(1,60,3)])\n",
    "    max_z = np.max([max_60[i] for i in range(2,60,3)])\n",
    "    min_x = np.min([min_60[i] for i in range(0,60,3)])\n",
    "    min_y = np.min([min_60[i] for i in range(1,60,3)])\n",
    "    min_z = np.min([min_60[i] for i in range(2,60,3)])\n",
    "    norm = np.zeros_like(video)\n",
    "    for i in range(0,60,3):\n",
    "        norm[:,i] = 2*(video[:,i]-min_x)/(max_x-min_x)-1\n",
    "        norm[:,i+1] = 2*(video[:,i+1]-min_y)/(max_y-min_y)-1\n",
    "        norm[:,i+2] = 2*(video[:,i+2]-min_z)/(max_z-min_z)-1\n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample ucla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_ucla(data):\n",
    "    dsamp = dict()\n",
    "    for key, val in data.items():\n",
    "        if val.shape[0] > 50:\n",
    "            new_val = np.zeros((50, 60))\n",
    "            diff = math.floor(val.shape[0]/50)\n",
    "            idx = 0\n",
    "            for i in range(0, val.shape[0], diff):\n",
    "                new_val[idx, :] = val[i, :]\n",
    "                idx += 1\n",
    "                if idx >= 50:\n",
    "                    break\n",
    "            dsamp.update({key: new_val})\n",
    "        else:\n",
    "            dsamp.update({key: val})\n",
    "    return dsamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feature, label pairs in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_label(raw_data,dsamp_data,max_len=50):\n",
    "    fea_xyz = []\n",
    "    labels = []\n",
    "    seq_len = []\n",
    "    for key, val in raw_data.items():\n",
    "        label = int(key[1:3])\n",
    "        if label ==11:\n",
    "            label = 7\n",
    "        elif label == 12:\n",
    "            label = 10\n",
    "        label -= 1\n",
    "        raw_len = val.shape[0]\n",
    "        if raw_len > max_len:\n",
    "            seq_len.append(max_len)\n",
    "            fea_xyz.append(dsamp_data[key])\n",
    "        else:\n",
    "            seq_len.append(raw_len)\n",
    "            pad_data = np.zeros((max_len,60))\n",
    "            pad_data[:raw_len,:] = dsamp_data[key]\n",
    "            fea_xyz.append(pad_data)\n",
    "        one_hot_label = np.zeros((10,))\n",
    "        one_hot_label[label] = 1.\n",
    "        labels.append(one_hot_label)\n",
    "    return fea_xyz,labels,seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete preprocess for ucla dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ucla(path):\n",
    "    # raw data\n",
    "    train_data, test_data = load_ucla_data(path)\n",
    "    # normalize\n",
    "    for key in train_data.keys():\n",
    "        train_data[key] = normalize_ucla(train_data[key])\n",
    "    for key in test_data.keys():\n",
    "        test_data[key] = normalize_ucla(test_data[key])\n",
    "    # down sample\n",
    "    dsamp_train = downsample_ucla(train_data)\n",
    "    dsamp_test = downsample_ucla(test_data)\n",
    "    # get features and labels pair\n",
    "    tr_fea_xyz,tr_label,tr_seq_len = get_feature_label(train_data,dsamp_train,max_len=50)\n",
    "    train_label = [np.argmax(tr_label[i]) for i in range(len(tr_label))]\n",
    "    te_fea_xyz,te_label,te_seq_len = get_feature_label(test_data,dsamp_test,max_len=50)\n",
    "    test_label = [np.argmax(te_label[i]) for i in range(len(te_label))]\n",
    "    return dsamp_train, dsamp_test, tr_fea_xyz, tr_label,tr_seq_len, te_fea_xyz, te_label, te_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One line code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  1019\n",
      "Size of test data:  463\n"
     ]
    }
   ],
   "source": [
    "dsamp_train, dsamp_test, tr_fea_xyz, tr_label,tr_seq_len, te_fea_xyz, te_label, te_seq_len = preprocess_ucla(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FS class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "class Seq2SeqModelFS(object):\n",
    "    def __init__(self, max_seq_len, input_size, rnn_size, batch_size, lr, train_keep_prob,decay_rate=0.95,dtype=tf.float32):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.rnn_size = rnn_size\n",
    "        self.batch_size = tf.placeholder_with_default(batch_size,shape=())\n",
    "        self.input_size = input_size\n",
    "        self.lr = tf.Variable( float(lr), trainable=False, dtype=dtype )\n",
    "        self.learning_rate_decay_op = self.lr.assign( self.lr * decay_rate)\n",
    "        self.keep_prob = tf.placeholder_with_default(1.0,shape=())\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        print('rnn_size = {0}'.format(rnn_size))\n",
    "        \n",
    "        with tf.variable_scope(\"inputs\"):\n",
    "            self.enc_xyz = tf.placeholder(dtype, shape=[None, self.max_seq_len, input_size], name='enc_xyz')\n",
    "            self.dec_xyz = tf.placeholder(dtype, shape=[None, self.max_seq_len, input_size], name='dec_xyz')\n",
    "            self.seq_len = tf.placeholder(tf.int32,[None])\n",
    "            mask = tf.sign(tf.reduce_max(tf.abs(self.enc_xyz[:,1:,:]), 2))\n",
    "\n",
    "        with tf.variable_scope(\"prediction\"):\n",
    "            with tf.variable_scope(\"encoder\"):\n",
    "                with tf.variable_scope(\"encoder_xyz\",reuse=tf.AUTO_REUSE):\n",
    "                    cell_fw_xyz = [tf.nn.rnn_cell.GRUCell(self.rnn_size//2) for i in range(3)]\n",
    "                    cell_bw_xyz = [tf.nn.rnn_cell.GRUCell(self.rnn_size//2) for i in range(3)]\n",
    "                    tuple_xyz = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cell_fw_xyz,cell_bw_xyz,self.enc_xyz,dtype=tf.float32,sequence_length=self.seq_len)\n",
    "                    bi_xyz_h = tf.concat((tuple_xyz[1][-1],tuple_xyz[2][-1]),-1)\n",
    "                    self.bi_xyz_h = bi_xyz_h\n",
    "            self.knn_state = self.bi_xyz_h\n",
    "            with tf.variable_scope(\"decoder\"):\n",
    "                with tf.variable_scope(\"decoder_xyz\",reuse=tf.AUTO_REUSE):\n",
    "                    cell_xyz__ = tf.nn.rnn_cell.GRUCell(self.rnn_size)\n",
    "                    cell_xyz_ = LinearSpaceDecoderWrapper(cell_xyz__,self.input_size)\n",
    "                    cell_xyz = ResidualWrapper(cell_xyz_)\n",
    "                    def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "                        \"\"\"\n",
    "                        Loop function that allows to control input to the rnn cell and manipulate cell outputs.\n",
    "                        :param time: current time step\n",
    "                        :param cell_output: output from previous time step or None if time == 0\n",
    "                        :param cell_state: cell state from previous time step\n",
    "                        :param loop_state: custom loop state to share information between different iterations of this loop fn\n",
    "                        :return: tuple consisting of\n",
    "                          elements_finished: tensor of size [bach_size] which is True for sequences that have reached their end,\n",
    "                            needed because of variable sequence size\n",
    "                          next_input: input to next time step\n",
    "                          next_cell_state: cell state forwarded to next time step\n",
    "                          emit_output: The first return argument of raw_rnn. This is not necessarily the output of the RNN cell,\n",
    "                            but could e.g. be the output of a dense layer attached to the rnn layer.\n",
    "                          next_loop_state: loop state forwarded to the next time step\n",
    "                        \"\"\"\n",
    "                        if cell_output is None:\n",
    "                            # time == 0, used for initialization before first call to cell\n",
    "                            next_cell_state = self.bi_xyz_h\n",
    "                            # the emit_output in this case tells TF how future emits look\n",
    "                            emit_output = tf.zeros([self.input_size])\n",
    "                        else:\n",
    "                            # t > 0, called right after call to cell, i.e. cell_output is the output from time t-1.\n",
    "                            # here you can do whatever ou want with cell_output before assigning it to emit_output.\n",
    "                            # In this case, we don't do anything\n",
    "                            next_cell_state = self.bi_xyz_h#NOTE:IF NO-FS, use cell_state#\n",
    "                            emit_output = cell_output  \n",
    "\n",
    "                        # check which elements are finished\n",
    "                        elements_finished = (time >= self.seq_len-1)\n",
    "                        finished = tf.reduce_all(elements_finished)\n",
    "\n",
    "                        # assemble cell input for upcoming time step\n",
    "                        current_output = emit_output if cell_output is not None else None\n",
    "                        #input_original = inputs_ta.read(time)  # tensor of shape (None, input_dim)\n",
    "                        input_original = self.enc_xyz[:,0,:]\n",
    "                        if current_output is None:\n",
    "                            # this is the initial step, i.e. there is no output from a previous time step, what we feed here\n",
    "                            # can highly depend on the data. In this case we just assign the actual input in the first time step.\n",
    "                            next_in = input_original\n",
    "                        else:\n",
    "                            # time > 0, so just use previous output as next input\n",
    "                            # here you could do fancier things, whatever you want to do before passing the data into the rnn cell\n",
    "                            # if here you were to pass input_original than you would get the normal behaviour of dynamic_rnn\n",
    "                            next_in = current_output\n",
    "\n",
    "                        next_input = tf.cond(finished,\n",
    "                                             lambda: tf.zeros([self.batch_size, self.input_size], dtype=tf.float32),  # copy through zeros\n",
    "                                             lambda: next_in)  # if not finished, feed the previous output as next input\n",
    "\n",
    "                        # set shape manually, otherwise it is not defined for the last dimensions\n",
    "                        next_input.set_shape([None, self.input_size])\n",
    "\n",
    "                        # loop state not used in this example\n",
    "                        next_loop_state = None\n",
    "                        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "                    outputs_ta, def_final_state_xyz, _ = tf.nn.raw_rnn(cell_xyz, loop_fn)\n",
    "                    self.dec_outputs_xyz = _transpose_batch_time(outputs_ta.stack())\n",
    "            def loss_with_mask(pred,gt,mask):\n",
    "                loss = tf.reduce_sum(tf.abs(pred-gt),2)*mask\n",
    "                loss = tf.reduce_sum(loss,1)\n",
    "                loss /= tf.reduce_sum(mask,1)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "                return loss\n",
    "        with tf.variable_scope(\"pred_xyz\",reuse=tf.AUTO_REUSE):\n",
    "            pred_xyz2xyz = self.dec_outputs_xyz\n",
    "            self.loss = loss_with_mask(pred_xyz2xyz,self.enc_xyz[:,1:,:],mask)\n",
    "        \n",
    "        opt = tf.train.AdamOptimizer(self.lr)\n",
    "        gradients, self.pred_vars = zip(*opt.compute_gradients(self.loss))\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(gradients, 25)\n",
    "        self.updates = opt.apply_gradients(zip(clipped_gradients,self.pred_vars),global_step = self.global_step)\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "    \n",
    "    def step(self, session, encoder_inputs_xyz,decoder_inputs_xyz,seq_len,forward_only):\n",
    "        if not forward_only:\n",
    "            input_feed = {self.enc_xyz: encoder_inputs_xyz,\n",
    "                          self.dec_xyz: decoder_inputs_xyz,\n",
    "                          self.seq_len: seq_len}\n",
    "            output_feed = [self.updates,self.loss]\n",
    "            outputs = session.run(output_feed, input_feed)\n",
    "            return outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FW class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModelFW(object):\n",
    "    def __init__(self, max_seq_len, input_size, rnn_size, batch_size, lr, train_keep_prob,decay_rate=0.95,dtype=tf.float32):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.rnn_size = rnn_size\n",
    "        self.batch_size = tf.placeholder_with_default(batch_size,shape=())\n",
    "        self.input_size = input_size\n",
    "        self.lr = tf.Variable( float(lr), trainable=False, dtype=dtype)\n",
    "        self.learning_rate_decay_op = self.lr.assign( self.lr * decay_rate)\n",
    "        self.keep_prob = tf.placeholder_with_default(1.0,shape=())\n",
    "\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        print('rnn_size = {0}'.format(rnn_size))\n",
    "        \n",
    "        with tf.variable_scope(\"inputs\"):\n",
    "            self.enc_xyz = tf.placeholder(dtype, shape=[None, self.max_seq_len, input_size], name='enc_xyz')\n",
    "            self.dec_xyz = tf.placeholder(dtype, shape=[None, self.max_seq_len, input_size], name='dec_xyz')\n",
    "            self.seq_len = tf.placeholder(tf.int32,[None])\n",
    "            mask = tf.sign(tf.reduce_max(tf.abs(self.enc_xyz), 2))\n",
    "        with tf.variable_scope(\"prediction\"):\n",
    "            with tf.variable_scope(\"encoder\"):\n",
    "                with tf.variable_scope(\"encoder_xyz\",reuse=tf.AUTO_REUSE):\n",
    "                    cell_fw_xyz = [tf.nn.rnn_cell.GRUCell(self.rnn_size//2) for i in range(3)]\n",
    "                    cell_bw_xyz = [tf.nn.rnn_cell.GRUCell(self.rnn_size//2) for i in range(3)]\n",
    "                    tuple_xyz = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cell_fw_xyz,cell_bw_xyz,self.enc_xyz,dtype=tf.float32,sequence_length=self.seq_len)\n",
    "                    bi_xyz_h = tf.concat((tuple_xyz[1][-1],tuple_xyz[2][-1]),-1)\n",
    "                    self.enc_states = tuple_xyz[0] #all encoder states [batch,time,2048]\n",
    "                    self.bi_xyz_h = bi_xyz_h\n",
    "            self.knn_state = self.bi_xyz_h\n",
    "            with tf.variable_scope(\"decoder\"):\n",
    "                with tf.variable_scope(\"decoder_xyz\",reuse=tf.AUTO_REUSE):\n",
    "                    cell_xyz = tf.nn.rnn_cell.GRUCell(self.rnn_size)\n",
    "                    self.dec_outputs_xyz, dec_final_state_xyz = tf.nn.dynamic_rnn(cell_xyz, tf.zeros_like(self.dec_xyz), sequence_length=self.seq_len,\\\n",
    "                                                                     initial_state = self.bi_xyz_h,dtype = tf.float32)\n",
    "            def loss_with_mask(pred,gt,mask):\n",
    "                loss = tf.reduce_sum(tf.abs(pred-gt),2)*mask\n",
    "                loss = tf.reduce_sum(loss,1)\n",
    "                loss /= tf.reduce_sum(mask,1)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "                return loss\n",
    "            with tf.variable_scope(\"pred_xyz\",reuse=tf.AUTO_REUSE):\n",
    "                FC = tf.layers.Dense(units=60,activation=None, name=\"pred_skel\")\n",
    "                pred_xyz2xyz = FC(self.dec_outputs_xyz)\n",
    "            self.loss = loss_with_mask(pred_xyz2xyz,self.enc_xyz,mask)\n",
    "        \n",
    "        self.pred_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"prediction/encoder\")\n",
    "#         self.fc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"prediction/pred_xyz\")\n",
    "        params = self.pred_vars #+ self.fc_vars\n",
    "        opt = tf.train.AdamOptimizer(self.lr)\n",
    "        gradients, self.pred_vars = zip(*opt.compute_gradients(self.loss))\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(gradients, 25)\n",
    "        self.updates = opt.apply_gradients(zip(clipped_gradients,self.pred_vars),global_step = self.global_step)\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "    \n",
    "    def step(self, session, encoder_inputs_xyz,decoder_inputs_xyz,seq_len,forward_only):\n",
    "        \n",
    "        if not forward_only:\n",
    "            input_feed = {self.enc_xyz: encoder_inputs_xyz,\n",
    "                          self.dec_xyz: decoder_inputs_xyz,\n",
    "                          self.seq_len: seq_len}\n",
    "            output_feed = [self.updates,self.loss]\n",
    "            outputs = session.run(output_feed, input_feed)\n",
    "            return outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear wrapper for FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import RNNCell\n",
    "class LinearSpaceDecoderWrapper(RNNCell):\n",
    "  \"\"\"Operator adding a linear encoder to an RNN cell\"\"\"\n",
    "\n",
    "  def __init__(self, cell, output_size):\n",
    "    \"\"\"Create a cell with with a linear encoder in space.\n",
    "\n",
    "    Args:\n",
    "      cell: an RNNCell. The input is passed through a linear layer.\n",
    "\n",
    "    Raises:\n",
    "      TypeError: if cell is not an RNNCell.\n",
    "    \"\"\"\n",
    "    if not isinstance(cell, RNNCell):\n",
    "      raise TypeError(\"The parameter cell is not a RNNCell.\")\n",
    "\n",
    "    self._cell = cell\n",
    "\n",
    "    print( 'output_size = {0}'.format(output_size) )\n",
    "    print( ' state_size = {0}'.format(self._cell.state_size) )\n",
    "\n",
    "    # Tuple if multi-rnn\n",
    "    if isinstance(self._cell.state_size,tuple):\n",
    "\n",
    "      # Fine if GRU...\n",
    "      insize = self._cell.state_size[-1]\n",
    "\n",
    "      # LSTMStateTuple if LSTM\n",
    "      if isinstance( insize, LSTMStateTuple ):\n",
    "        insize = insize.h\n",
    "\n",
    "    else:\n",
    "      # Fine if not multi-rnn\n",
    "      insize = self._cell.state_size\n",
    "\n",
    "    self.w_out = tf.get_variable(\"proj_w_out\",\n",
    "        [insize, output_size],\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.random_uniform_initializer(minval=-0.04, maxval=0.04))\n",
    "    self.b_out = tf.get_variable(\"proj_b_out\", [output_size],\n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.random_uniform_initializer(minval=-0.04, maxval=0.04))\n",
    "\n",
    "    self.linear_output_size = output_size\n",
    "\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._cell.state_size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self.linear_output_size\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    \"\"\"Use a linear layer and pass the output to the cell.\"\"\"\n",
    "\n",
    "    # Run the rnn as usual\n",
    "    output, new_state = self._cell(inputs, state, scope)\n",
    "\n",
    "    # Apply the multiplication to everything\n",
    "    output = tf.matmul(output, self.w_out) + self.b_out\n",
    "\n",
    "    return output, new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Wrapper for FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualWrapper(RNNCell):\n",
    "  \"\"\"Operator adding residual connections to a given cell.\"\"\"\n",
    "\n",
    "  def __init__(self, cell):\n",
    "    \"\"\"Create a cell with added residual connection.\n",
    "\n",
    "    Args:\n",
    "      cell: an RNNCell. The input is added to the output.\n",
    "\n",
    "    Raises:\n",
    "      TypeError: if cell is not an RNNCell.\n",
    "    \"\"\"\n",
    "    if not isinstance(cell, RNNCell):\n",
    "      raise TypeError(\"The parameter cell is not a RNNCell.\")\n",
    "\n",
    "    self._cell = cell\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._cell.state_size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._cell.output_size\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    \"\"\"Run the cell and add a residual connection.\"\"\"\n",
    "\n",
    "    # Run the rnn as usual\n",
    "    output, new_state = self._cell(inputs, state, scope)\n",
    "\n",
    "    # Add the residual connection\n",
    "    output = tf.add(output, inputs)\n",
    "\n",
    "    return output, new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get learned Features for knn evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(model, session, encoder_inputs_xyz, batch_size, seq_len):\n",
    "    input_feed = {model.enc_xyz: encoder_inputs_xyz,\n",
    "                  model.dec_xyz: encoder_inputs_xyz,\n",
    "                  model.seq_len: seq_len, model.batch_size:batch_size}\n",
    "    output_feed = [model.knn_state]\n",
    "    outputs = session.run(output_feed, input_feed)\n",
    "    return outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    \"\"\"Create a session that dynamically allocates memory.\"\"\"\n",
    "    # See: https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
    "    config = tf.ConfigProto(log_device_placement=True,allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(data, seq_len, input_size, batch_size):\n",
    "    #encoder inputs\n",
    "    encoder_inputs_xyz = np.zeros((batch_size, seq_len, input_size),dtype=float)\n",
    "    #length\n",
    "    seq_len_enc = np.zeros((batch_size,), dtype=float)\n",
    "    #decoder inputs\n",
    "    decoder_inputs_xyz = np.zeros((batch_size, seq_len, input_size),dtype=float)\n",
    "    data_len = len(data)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        key = random.choice(list(data.keys()))\n",
    "        data_sel = data[key]\n",
    "        encoder_inputs_xyz[i, :data_sel.shape[0], :] = np.copy(data_sel)\n",
    "        seq_len_enc[i] = data_sel.shape[0]\n",
    "        \n",
    "    return encoder_inputs_xyz, decoder_inputs_xyz, seq_len_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batch for evaluating learned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_classify(feature_xyz,labels,seq_len,batch_size):\n",
    "    for start in range(0,len(feature_xyz),batch_size):\n",
    "        end = min(start+batch_size,len(feature_xyz))\n",
    "        yield feature_xyz[start:end],labels[start:end],seq_len[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len=50\n",
    "rnn_size=2048\n",
    "input_size = 60\n",
    "batch_size=64\n",
    "lr = .0001\n",
    "train_keep_prob = 1.0\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training FW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sukun/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "rnn_size = 2048\n",
      "WARNING:tensorflow:From <ipython-input-12-adcec0763b40>:22: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/sukun/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/sukun/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/sukun/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# FW\n",
    "model = Seq2SeqModelFW(max_seq_len, input_size,rnn_size, batch_size, lr,train_keep_prob)\n",
    "sess = get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FW Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:  train loss:23.8788 using 2.81 sec\n",
      "KNN test score: 0.7451403887688985\n",
      "step 100:  train loss:7.2764 using 74.27 sec\n",
      "KNN test score: 0.7537796976241901\n",
      "WARNING:tensorflow:From /home/sukun/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "step 200:  train loss:6.0994 using 76.06 sec\n",
      "KNN test score: 0.7580993520518359\n",
      "step 300:  train loss:5.8068 using 79.12 sec\n",
      "KNN test score: 0.7602591792656588\n",
      "step 400:  train loss:5.0657 using 78.89 sec\n",
      "KNN test score: 0.7645788336933045\n",
      "step 500:  train loss:5.1571 using 77.96 sec\n",
      "KNN test score: 0.7861771058315334\n",
      "step 600:  train loss:4.7311 using 76.71 sec\n",
      "KNN test score: 0.7991360691144709\n",
      "step 700:  train loss:4.5220 using 77.87 sec\n",
      "KNN test score: 0.7926565874730022\n",
      "step 800:  train loss:4.3473 using 79.54 sec\n",
      "KNN test score: 0.8120950323974082\n",
      "step 900:  train loss:4.0523 using 78.28 sec\n",
      "KNN test score: 0.8056155507559395\n",
      "step 1000:  train loss:4.0832 using 76.42 sec\n",
      "KNN test score: 0.8077753779697624\n",
      "step 1100:  train loss:3.6434 using 74.77 sec\n",
      "KNN test score: 0.8142548596112311\n",
      "step 1200:  train loss:4.0100 using 76.21 sec\n",
      "KNN test score: 0.8056155507559395\n",
      "step 1300:  train loss:3.5625 using 77.02 sec\n",
      "KNN test score: 0.8142548596112311\n",
      "step 1400:  train loss:3.5559 using 76.39 sec\n",
      "KNN test score: 0.8142548596112311\n",
      "step 1500:  train loss:3.4848 using 72.55 sec\n",
      "KNN test score: 0.816414686825054\n",
      "step 1600:  train loss:3.4606 using 74.35 sec\n",
      "KNN test score: 0.816414686825054\n",
      "step 1700:  train loss:3.3213 using 72.21 sec\n",
      "KNN test score: 0.8142548596112311\n",
      "step 1800:  train loss:3.3195 using 72.19 sec\n",
      "KNN test score: 0.8142548596112311\n",
      "step 1900:  train loss:3.4061 using 72.23 sec\n",
      "KNN test score: 0.8250539956803455\n",
      "step 2000:  train loss:3.1234 using 73.22 sec\n",
      "KNN test score: 0.8185745140388769\n",
      "step 2100:  train loss:3.1608 using 72.21 sec\n",
      "KNN test score: 0.816414686825054\n",
      "step 2200:  train loss:3.1217 using 72.24 sec\n",
      "KNN test score: 0.8250539956803455\n",
      "step 2300:  train loss:3.2416 using 72.18 sec\n",
      "KNN test score: 0.8250539956803455\n",
      "step 2400:  train loss:3.3346 using 72.21 sec\n",
      "KNN test score: 0.8272138228941684\n",
      "step 2500:  train loss:2.9229 using 78.86 sec\n",
      "KNN test score: 0.8272138228941684\n",
      "step 2600:  train loss:3.1581 using 76.00 sec\n",
      "KNN test score: 0.8293736501079914\n",
      "step 2700:  train loss:3.1065 using 74.76 sec\n",
      "KNN test score: 0.8272138228941684\n",
      "step 2800:  train loss:2.7920 using 76.46 sec\n",
      "KNN test score: 0.8272138228941684\n",
      "step 2900:  train loss:3.0207 using 76.48 sec\n",
      "KNN test score: 0.8272138228941684\n",
      "step 3000:  train loss:2.8082 using 72.17 sec\n",
      "KNN test score: 0.8185745140388769\n",
      "step 3100:  train loss:2.8531 using 72.12 sec\n",
      "KNN test score: 0.8228941684665226\n",
      "step 3200:  train loss:2.9188 using 72.22 sec\n",
      "KNN test score: 0.8207343412526998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a3022f3ea80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mencoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsamp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     for encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc in mini_batch(dsamp_train, seq_len=50, input_size=60, batch_size=64):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         _,train_loss = model.step(sess,encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc, False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-adcec0763b40>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, encoder_inputs_xyz, decoder_inputs_xyz, seq_len, forward_only)\u001b[0m\n\u001b[1;32m     59\u001b[0m                           self.seq_len: seq_len}\n\u001b[1;32m     60\u001b[0m             \u001b[0moutput_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = []\n",
    "loss = []\n",
    "max_score = 0\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(0,iterations+1):\n",
    "    encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc = mini_batch(dsamp_train, seq_len=50, input_size=60, batch_size=64)\n",
    "    _,train_loss = model.step(sess,encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc, False)\n",
    "    if i%100 == 0:\n",
    "        loss.append(train_loss)\n",
    "        print(\"step {0}:  train loss:{1:.4f}\".format(i, train_loss),end='')\n",
    "        end_time = timeit.default_timer()\n",
    "        print(\" using {:.2f} sec\".format(end_time-start_time))\n",
    "        start_time = end_time\n",
    "        knn_feature = []\n",
    "        j = 0\n",
    "        for feature_xyz,labels,seq_len in mini_batch_classify(tr_fea_xyz,tr_label,tr_seq_len,batch_size):\n",
    "            j +=1\n",
    "            result = get_feature(model, sess, feature_xyz, len(feature_xyz), seq_len)\n",
    "            knn_feature.append(result)\n",
    "        knn_feature = np.vstack(knn_feature)\n",
    "        test_knn_feature = []\n",
    "        j = 0\n",
    "        for feature_xyz,labels,seq_len in mini_batch_classify(te_fea_xyz,te_label,te_seq_len,batch_size):\n",
    "            j +=1\n",
    "            result = get_feature(model, sess, feature_xyz,len(feature_xyz),seq_len)\n",
    "            test_knn_feature.append(result)\n",
    "        test_knn_feature = np.vstack(test_knn_feature)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "        neigh.fit(knn_feature, np.argmax(tr_label,axis=1))\n",
    "        current_score = neigh.score(test_knn_feature, np.argmax(te_label,axis=1))\n",
    "        print(\"KNN test score:\",current_score)\n",
    "        score.append(current_score)\n",
    "        if current_score>max_score:\n",
    "            max_score = current_score\n",
    "            model.saver.save(sess,\"ucla_model/FW\",global_step=i)\n",
    "    if i%1000 == 0:\n",
    "        sess.run(model.learning_rate_decay_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FW Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trained FW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_size = 2048\n",
      "INFO:tensorflow:Restoring parameters from ucla_model/FW-2600\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "model = Seq2SeqModelFW(max_seq_len, 60,rnn_size, batch_size, lr,train_keep_prob)\n",
    "sess = get_session()\n",
    "model.saver.restore(sess,\"ucla_model/FW-2600\") #\"FW-$number of step\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_feature = []\n",
    "j = 0\n",
    "for feature_xyz,labels,seq_len in mini_batch_classify(tr_fea_xyz,tr_label,tr_seq_len,batch_size):\n",
    "    j +=1\n",
    "    result = get_feature(model, sess, feature_xyz, len(feature_xyz), seq_len)\n",
    "    knn_feature.append(result)\n",
    "knn_feature = np.vstack(knn_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knn_feature = []\n",
    "j = 0\n",
    "for feature_xyz,labels,seq_len in mini_batch_classify(te_fea_xyz,te_label,te_seq_len,batch_size):\n",
    "    j +=1\n",
    "    result = get_feature(model, sess, feature_xyz,len(feature_xyz),seq_len)\n",
    "    test_knn_feature.append(result)\n",
    "test_knn_feature = np.vstack(test_knn_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 7928 epoch knn score 0.829\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "neigh.fit(knn_feature,np.argmax(tr_label,axis=1))\n",
    "t_score = neigh.score(test_knn_feature,np.argmax(te_label,axis=1))\n",
    "print(\"after {0} epoch knn score {1:.3f}\".format(epoch,t_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple structure for AEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEC(object):\n",
    "    def __init__(self, input_size, batch_size, lr, dtype=tf.float32):\n",
    "       \n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, input_size], name='X')\n",
    "\n",
    "        #encoder\n",
    "        self.fc1 = tf.layers.dense(self.X,1024,activation='tanh')\n",
    "        self.fc2 = tf.layers.dense(self.fc1,512,activation='tanh')\n",
    "        self.fea = tf.layers.dense(self.fc2,256,activation='tanh')\n",
    "\n",
    "        #decoder\n",
    "        self.fc3 = tf.layers.dense(self.fea,512,activation='tanh')\n",
    "        self.fc4 = tf.layers.dense(self.fc3,1024,activation='tanh')\n",
    "        self.Y = tf.layers.dense(self.fc4,input_size,activation=None)\n",
    "\n",
    "        self.loss = tf.reduce_mean(tf.square(self.X-self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(lr)\n",
    "        self.opt = self.optimizer.minimize(self.loss)\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "    \n",
    "    def step(self, session, feature, forward_only=False):\n",
    "        \n",
    "        if forward_only:\n",
    "            output = sess.run([self.fea],feed_dict={self.X:feature})\n",
    "            return output\n",
    "        else:\n",
    "            _,train_loss = sess.run([self.opt,self.loss],feed_dict={self.X:feature})\n",
    "            return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEC training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "input_size = 2048\n",
    "batch_size = 16\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "aec_model = AEC(input_size, batch_size, lr)\n",
    "sess = get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aec_mini_batch_classify(feature_xyz,batch_size):\n",
    "    for start in range(0,len(feature_xyz),batch_size):\n",
    "        end = min(start+batch_size,len(feature_xyz))\n",
    "        yield feature_xyz[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 epoch knn score 0.842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-ebe02e43c895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maec_mini_batch_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#         print(\"epoch:{0},loss:{1}\".format(epoch,train_loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-23ef7b2d6c34>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, feature, forward_only)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aec_score = 0\n",
    "for epoch in range(epochs):\n",
    "    for feature in aec_mini_batch_classify(knn_feature,batch_size):\n",
    "        train_loss = aec_model.step(sess,feature)\n",
    "#         print(\"epoch:{0},loss:{1}\".format(epoch,train_loss))\n",
    "    if epoch % 1000 == 0:\n",
    "        denoise_all = []\n",
    "        for feature in aec_mini_batch_classify(knn_feature,batch_size):\n",
    "            denoise = aec_model.step(sess,feature,forward_only=True)\n",
    "            denoise_all.append(denoise[0])\n",
    "        see = np.vstack(denoise_all)\n",
    "            \n",
    "        test_denoise_all = []\n",
    "        for feature in aec_mini_batch_classify(test_knn_feature,batch_size):\n",
    "            denoise = aec_model.step(sess,feature,forward_only=True)\n",
    "            test_denoise_all.append(denoise[0])\n",
    "        test_see = np.vstack(test_denoise_all)\n",
    "        \n",
    "        neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "        neigh.fit(see,np.argmax(tr_label,axis=1))\n",
    "        t_score = neigh.score(test_see,np.argmax(te_label,axis=1))\n",
    "        print(\"after {0} epoch knn score {1:.3f}\".format(epoch,t_score))\n",
    "        if t_score>aec_score:\n",
    "            aec_score = current_score\n",
    "            model.saver.save(sess,\"ucla_model/FW-AEC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len=50\n",
    "rnn_size=2048\n",
    "input_size = 60\n",
    "batch_size=64\n",
    "lr = .0001\n",
    "train_keep_prob = 1.0\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_size = 2048\n",
      "output_size = 60\n",
      " state_size = 2048\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# FS\n",
    "model = Seq2SeqModelFS(max_seq_len, input_size,rnn_size, batch_size, lr,train_keep_prob)\n",
    "sess = get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:  train loss:121.8500 using 2.18 sec\n",
      "KNN test score: 0.7408207343412527\n",
      "step 100:  train loss:12.4162 using 73.64 sec\n",
      "KNN test score: 0.7796976241900648\n",
      "step 200:  train loss:10.0450 using 73.88 sec\n",
      "KNN test score: 0.7948164146868251\n",
      "step 300:  train loss:9.1190 using 75.43 sec\n",
      "KNN test score: 0.8056155507559395\n",
      "step 400:  train loss:9.1730 using 72.85 sec\n",
      "KNN test score: 0.7991360691144709\n",
      "step 500:  train loss:9.1789 using 73.34 sec\n",
      "KNN test score: 0.7883369330453563\n",
      "step 600:  train loss:8.4541 using 71.92 sec\n",
      "KNN test score: 0.8099352051835853\n",
      "step 700:  train loss:8.0992 using 73.01 sec\n",
      "KNN test score: 0.7991360691144709\n",
      "step 800:  train loss:7.7977 using 72.07 sec\n",
      "KNN test score: 0.8099352051835853\n",
      "step 900:  train loss:7.4648 using 72.73 sec\n",
      "KNN test score: 0.8185745140388769\n",
      "step 1000:  train loss:7.7834 using 73.52 sec\n",
      "KNN test score: 0.8185745140388769\n",
      "step 1100:  train loss:7.3076 using 76.48 sec\n",
      "KNN test score: 0.8012958963282938\n",
      "step 1200:  train loss:7.4040 using 73.38 sec\n",
      "KNN test score: 0.796976241900648\n",
      "step 1300:  train loss:7.3462 using 73.29 sec\n",
      "KNN test score: 0.7948164146868251\n",
      "step 1400:  train loss:6.8975 using 73.47 sec\n",
      "KNN test score: 0.7926565874730022\n",
      "step 1500:  train loss:6.9174 using 73.33 sec\n",
      "KNN test score: 0.7818574514038877\n",
      "step 1600:  train loss:6.7627 using 74.83 sec\n",
      "KNN test score: 0.775377969762419\n",
      "step 1700:  train loss:6.8486 using 77.40 sec\n",
      "KNN test score: 0.7732181425485961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-c893b1c71c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mencoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsamp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_inputs_xyz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b676279cb9e5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, encoder_inputs_xyz, decoder_inputs_xyz, seq_len, forward_only)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           self.seq_len: seq_len}\n\u001b[1;32m    113\u001b[0m             \u001b[0moutput_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = []\n",
    "loss = []\n",
    "max_score = 0\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(0,iterations+1):\n",
    "    encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc = mini_batch(dsamp_train, seq_len=50, input_size=60, batch_size=64)\n",
    "    _,train_loss = model.step(sess,encoder_inputs_xyz,decoder_inputs_xyz,seq_len_enc, False)\n",
    "    if i%100 == 0:\n",
    "        loss.append(train_loss)\n",
    "        print(\"step {0}:  train loss:{1:.4f}\".format(i, train_loss),end='')\n",
    "        end_time = timeit.default_timer()\n",
    "        print(\" using {:.2f} sec\".format(end_time-start_time))\n",
    "        start_time = end_time\n",
    "        knn_feature = []\n",
    "        j = 0\n",
    "        for feature_xyz,labels,seq_len in mini_batch_classify(tr_fea_xyz,tr_label,tr_seq_len,batch_size):\n",
    "            j +=1\n",
    "            result = get_feature(model, sess, feature_xyz, len(feature_xyz), seq_len)\n",
    "            knn_feature.append(result)\n",
    "        knn_feature = np.vstack(knn_feature)\n",
    "        test_knn_feature = []\n",
    "        j = 0\n",
    "        for feature_xyz,labels,seq_len in mini_batch_classify(te_fea_xyz,te_label,te_seq_len,batch_size):\n",
    "            j +=1\n",
    "            result = get_feature(model, sess, feature_xyz,len(feature_xyz),seq_len)\n",
    "            test_knn_feature.append(result)\n",
    "        test_knn_feature = np.vstack(test_knn_feature)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "        neigh.fit(knn_feature, np.argmax(tr_label,axis=1))\n",
    "        current_score = neigh.score(test_knn_feature, np.argmax(te_label,axis=1))\n",
    "        print(\"KNN test score:\",current_score)\n",
    "        score.append(current_score)\n",
    "        if current_score>max_score:\n",
    "            max_score = current_score\n",
    "            model.saver.save(sess,\"ucla_model/FS\",global_step=i)\n",
    "    if i%1000 == 0:\n",
    "        sess.run(model.learning_rate_decay_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get FS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_size = 2048\n",
      "output_size = 60\n",
      " state_size = 2048\n",
      "INFO:tensorflow:Restoring parameters from ucla_model/FS-900\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "model = Seq2SeqModelFS(max_seq_len, 60,rnn_size, batch_size, lr,train_keep_prob)\n",
    "sess = get_session()\n",
    "model.saver.restore(sess,\"ucla_model/FS-900\") #\"FW-$number of step\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve FS model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_feature = []\n",
    "j = 0\n",
    "for feature_xyz,labels,seq_len in mini_batch_classify(tr_fea_xyz,tr_label,tr_seq_len,batch_size):\n",
    "    j +=1\n",
    "    result = get_feature(model, sess, feature_xyz, len(feature_xyz), seq_len)\n",
    "    knn_feature.append(result)\n",
    "knn_feature = np.vstack(knn_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knn_feature = []\n",
    "j = 0\n",
    "for feature_xyz,labels,seq_len in mini_batch_classify(te_fea_xyz,te_label,te_seq_len,batch_size):\n",
    "    j +=1\n",
    "    result = get_feature(model, sess, feature_xyz,len(feature_xyz),seq_len)\n",
    "    test_knn_feature.append(result)\n",
    "test_knn_feature = np.vstack(test_knn_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best score from FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 54 epoch knn score 0.819\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "neigh.fit(knn_feature,np.argmax(tr_label,axis=1))\n",
    "t_score = neigh.score(test_knn_feature,np.argmax(te_label,axis=1))\n",
    "print(\"after {0} epoch knn score {1:.3f}\".format(epoch,t_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEC for FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "input_size = 2048\n",
    "batch_size = 16\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "aec_model = AEC(input_size, batch_size, lr)\n",
    "sess = get_session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645788336933045\n",
      "0.796976241900648\n",
      "0.7991360691144709\n",
      "0.8034557235421166\n",
      "0.8056155507559395\n",
      "0.8056155507559395\n",
      "0.796976241900648\n",
      "0.7991360691144709\n",
      "0.7991360691144709\n",
      "0.7926565874730022\n",
      "0.7991360691144709\n",
      "0.8034557235421166\n",
      "0.8012958963282938\n",
      "0.8034557235421166\n",
      "0.8056155507559395\n",
      "0.7991360691144709\n",
      "0.8012958963282938\n",
      "0.8120950323974082\n",
      "0.8056155507559395\n",
      "0.8034557235421166\n",
      "0.8120950323974082\n",
      "0.8099352051835853\n",
      "0.8034557235421166\n",
      "0.8120950323974082\n",
      "0.8120950323974082\n",
      "0.8099352051835853\n",
      "0.8185745140388769\n",
      "0.8120950323974082\n",
      "0.8099352051835853\n",
      "0.8056155507559395\n",
      "0.8012958963282938\n",
      "0.8056155507559395\n",
      "0.8077753779697624\n",
      "0.8142548596112311\n",
      "0.8077753779697624\n",
      "0.8056155507559395\n",
      "0.8120950323974082\n",
      "0.8142548596112311\n",
      "0.8120950323974082\n",
      "0.816414686825054\n",
      "0.8056155507559395\n",
      "0.8099352051835853\n",
      "0.816414686825054\n",
      "0.8120950323974082\n",
      "0.8142548596112311\n",
      "0.816414686825054\n",
      "0.8142548596112311\n",
      "0.8142548596112311\n",
      "0.8142548596112311\n",
      "0.8077753779697624\n",
      "0.8207343412526998\n",
      "0.8056155507559395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-d4f8ebe5ebb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maec_mini_batch_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdenoise_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-23ef7b2d6c34>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, feature, forward_only)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aec_score = 0\n",
    "for epoch in range(epochs):\n",
    "    for feature in aec_mini_batch_classify(knn_feature,batch_size):\n",
    "        train_loss = aec_model.step(sess,feature)\n",
    "    if epoch % 100 == 0:\n",
    "        denoise_all = []\n",
    "        for feature in aec_mini_batch_classify(knn_feature,batch_size):\n",
    "            denoise = aec_model.step(sess,feature,forward_only=True)\n",
    "            denoise_all.append(denoise[0])\n",
    "        see = np.vstack(denoise_all)\n",
    "            \n",
    "        test_denoise_all = []\n",
    "        for feature in aec_mini_batch_classify(test_knn_feature,batch_size):\n",
    "            denoise = aec_model.step(sess,feature,forward_only=True)\n",
    "            test_denoise_all.append(denoise[0])\n",
    "        test_see = np.vstack(test_denoise_all)\n",
    "        \n",
    "        neigh = KNeighborsClassifier(n_neighbors=1,metric='cosine')\n",
    "        neigh.fit(see,np.argmax(tr_label,axis=1))\n",
    "        t_score = neigh.score(test_see,np.argmax(te_label,axis=1))\n",
    "        print(t_score)\n",
    "        if t_score>aec_score:\n",
    "            aec_score = current_score\n",
    "            model.saver.save(sess,\"ucla_model/FS-AEC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
